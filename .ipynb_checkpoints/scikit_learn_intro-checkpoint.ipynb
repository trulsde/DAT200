{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Import modules\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Load data and select features\n",
    "# ==============================================================================\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Split into training and test data\n",
    "# ==============================================================================\n",
    "\n",
    "# Print lables of all classes in data set\n",
    "print(\"Class labels:\", np.unique(y))\n",
    "\n",
    "\n",
    "# Split data into training and test data (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "# Show distribution of classes in input data, training data and test data\n",
    "print(f\"Labels counts in y: {np.bincount(y)}\")\n",
    "print(f\"Labels counts in y_train: {np.bincount(y_train)}\")\n",
    "print(f\"Labels counts in y_test: {np.bincount(y_test)}\")\n",
    "\n",
    "\n",
    "# Show distribution of classes in input data, training data and test data\n",
    "# Alternative 2\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Labels counts in y:\", unique, counts)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels counts in y_train:\", unique, counts)\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels counts in y_test:\", unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Scale features using StandardScaler class in scikit-learn\n",
    "# ==============================================================================\n",
    "\n",
    "# Initialise standard scaler and compute mean and stddev from training data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform (standardise) both X_train and X_test with mean and stddev from\n",
    "# training data\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "print(\"Mean of X_train_sc:\", np.mean(X_train_sc, axis=0))\n",
    "print(\"Stddev of X_train_sc:\", np.std(X_train_sc, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Train multiclass perceptron of scikit-learn\n",
    "# ==============================================================================\n",
    "\n",
    "# Initialise the model\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Make predictions for the test set\n",
    "# ==============================================================================\n",
    "\n",
    "# Predict classes for samples in test set and print number of misclassfications\n",
    "y_pred = ppn.predict(X_test_sc)\n",
    "print(\"Misclassified samples: {0}\".format((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Compute performance metrics\n",
    "# ==============================================================================\n",
    "\n",
    "# Print accuracy computed from predictions on the test set\n",
    "print(\"Accuracy: {0:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "# Print accuracy computed from predictions on the test set\n",
    "print(\"Accuracy: {0:.2f}\".format(ppn.score(X_test_sc, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Plot results with plot function for decision regions using scikit-learn\n",
    "# ==============================================================================\n",
    "\n",
    "X_combined_sc = np.vstack((X_train_sc, X_test_sc))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "plot = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=ppn,\n",
    "    X=X_combined_sc,\n",
    "    alpha=1.0,\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    xlabel=\"petal length [standardized]\",\n",
    "    ylabel=\"petal width [standardized]\",\n",
    ")\n",
    "\n",
    "plot.ax_.scatter(X_combined_sc[:, 0], X_combined_sc[:, 1], c=y_combined, marker=\"o\", edgecolor=\"k\")\n",
    "\n",
    "# Highlight test samples\n",
    "plot.ax_.scatter(\n",
    "    X_test_sc[:, 0],\n",
    "    X_test_sc[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=10,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "# Highlight misclassified test samples\n",
    "plot.ax_.scatter(\n",
    "    X_test_sc[y_test != y_pred, 0],\n",
    "    X_test_sc[y_test != y_pred, 1],\n",
    "    marker=\"o\",\n",
    "    s=10,\n",
    "    c=\"r\",\n",
    "    facecolors=\"none\",\n",
    "    label=\"misclassified\",\n",
    ")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Perceptron on Iris\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
