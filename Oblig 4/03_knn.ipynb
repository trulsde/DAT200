{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "#X, y = datasets.make_moons(n_samples=100, noise=0.1, random_state=42)\n",
    "X, y = datasets.make_classification(n_samples=200, n_features=3, n_informative=3, n_classes=2, n_redundant=0, n_clusters_per_class=4, random_state=42)\n",
    "\n",
    "# Only use the first two features and normalize the data\n",
    "X = X[:, [0,1]]\n",
    "\n",
    "# Split the data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "X_scaled = sc.transform(X)\n",
    "\n",
    "# Train k-nearest neighbors classifiers for k=1 to k=9\n",
    "clfs = []\n",
    "for k in range(1, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    clfs.append(knn)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "h = 0.05\n",
    "x_min, x_max = X_scaled[:, 0].min() - 1, X_scaled[:, 0].max() + 1\n",
    "y_min, y_max = X_scaled[:, 1].min() - 1, X_scaled[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X_predict = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "accuracy = []\n",
    "for clf, name, a in zip(clfs, [f\"{k}-Nearest-Neighbor\" for k in range(1, 10)], ax):\n",
    "    Z = clf.predict(X_predict).reshape(xx.shape)\n",
    "    a.contourf(xx, yy, Z)\n",
    "    a.set_title(f\"{name} decision boundary\")\n",
    "    # Plot the misclassified test and training points\n",
    "    test_accuracy = np.mean(clf.predict(X_test_scaled) == y_test)\n",
    "    train_accuracy = np.mean(clf.predict(X_train_scaled) == y_train)\n",
    "    print(\n",
    "        f\"{name} train accuracy: {train_accuracy:.3f}\"\n",
    "        f\"  test accuracy: {test_accuracy:.3f}\"\n",
    "    )\n",
    "    accuracy.append(test_accuracy)\n",
    "\n",
    "# Output the best k\n",
    "best_k = np.argmax(accuracy) + 1\n",
    "print(f\"Best k: {best_k}\")\n",
    "\n",
    "# Plot the data\n",
    "colors, markers = [\"blue\", \"limegreen\", \"gray\", \"cyan\"], \"s^oxv<>\"\n",
    "for a in ax:\n",
    "    for i in range(len(np.unique(y))):\n",
    "        a.scatter(X_scaled[y == i, 0], X_scaled[y == i, 1], color=colors[i], marker=markers[i], s=50, facecolors=\"none\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
